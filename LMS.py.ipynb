{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.3\n",
      "0.3\n",
      "Weight vector: [0.2 0.3 0.3]\n",
      "Final error: 0.5723016365138414\n",
      "final weight: [-0.06129428  0.17837274  0.26492659]\n",
      "1.0\n",
      "0.0\n",
      "0.2\n",
      "Weight vector: [1.  0.  0.2]\n",
      "Final error: 0.8305168200997312\n",
      "final weight: [0.15051279 0.26151509 0.13741131]\n",
      "0.1\n",
      "0.4\n",
      "0.1\n",
      "Weight vector: [0.1 0.4 0.1]\n",
      "Final error: 0.6149489645352544\n",
      "final weight: [-0.03483824  0.22026433  0.22547549]\n",
      "0.2\n",
      "0.3\n",
      "1.0\n",
      "Weight vector: [0.2 0.3 1. ]\n",
      "Final error: 0.4782527519509189\n",
      "final weight: [-0.20353503  0.04756237  0.40885286]\n",
      "0.9\n",
      "0.8\n",
      "0.6\n",
      "Weight vector: [0.9 0.8 0.6]\n",
      "Final error: 0.8930599331242661\n",
      "final weight: [0.16426723 0.33211346 0.09030132]\n",
      "0.1\n",
      "0.0\n",
      "0.3\n",
      "Weight vector: [0.1 0.  0.3]\n",
      "Final error: 0.5064954182164249\n",
      "final weight: [-0.13788933  0.10241569  0.34146831]\n",
      "0.3\n",
      "0.7\n",
      "0.1\n",
      "Weight vector: [0.3 0.7 0.1]\n",
      "Final error: 0.7762305277648197\n",
      "final weight: [0.07154371 0.31182273 0.12854532]\n",
      "0.5\n",
      "0.2\n",
      "0.6\n",
      "Weight vector: [0.5 0.2 0.6]\n",
      "Final error: 0.5700883178959472\n",
      "final weight: [-0.04849665  0.14899666  0.28416167]\n",
      "0.3\n",
      "0.5\n",
      "0.7\n",
      "Weight vector: [0.3 0.5 0.7]\n",
      "Final error: 0.5505549194315942\n",
      "final weight: [-0.08158238  0.15946244  0.28934621]\n",
      "0.4\n",
      "0.2\n",
      "0.1\n",
      "Weight vector: [0.4 0.2 0.1]\n",
      "Final error: 0.6632032463229339\n",
      "final weight: [0.02331699 0.22683128 0.20174564]\n",
      "0.2\n",
      "0.5\n",
      "0.4\n",
      "Weight vector: [0.2 0.5 0.4]\n",
      "Final error: 0.5903647520810343\n",
      "final weight: [-0.05040895  0.19992267  0.24805198]\n",
      "0.8\n",
      "0.0\n",
      "0.5\n",
      "Weight vector: [0.8 0.  0.5]\n",
      "Final error: 0.6494743208830367\n",
      "final weight: [0.02997869 0.17425079 0.23987091]\n",
      "0.6\n",
      "0.9\n",
      "0.7\n",
      "Weight vector: [0.6 0.9 0.7]\n",
      "Final error: 0.7465106454140807\n",
      "final weight: [0.07018917 0.28674075 0.15330983]\n",
      "1.0\n",
      "0.2\n",
      "0.0\n",
      "Weight vector: [1.  0.2 0. ]\n",
      "Final error: 0.9873780253536465\n",
      "final weight: [0.22235844 0.33912661 0.05885401]\n",
      "0.3\n",
      "0.7\n",
      "0.6\n",
      "Weight vector: [0.3 0.7 0.6]\n",
      "Final error: 0.6141149789148587\n",
      "final weight: [-0.03005683  0.21838676  0.2313498 ]\n",
      "0.7\n",
      "0.7\n",
      "0.8\n",
      "Weight vector: [0.7 0.7 0.8]\n",
      "Final error: 0.693172911775353\n",
      "final weight: [0.04845052 0.24341779 0.19091778]\n",
      "0.2\n",
      "0.3\n",
      "0.1\n",
      "Weight vector: [0.2 0.3 0.1]\n",
      "Final error: 0.62115138623152\n",
      "final weight: [-0.02065407  0.21574713  0.22380479]\n",
      "0.5\n",
      "0.4\n",
      "0.3\n",
      "Weight vector: [0.5 0.4 0.3]\n",
      "Final error: 0.6922417330745166\n",
      "final weight: [0.04366911 0.24529537 0.18504347]\n",
      "0.9\n",
      "0.1\n",
      "0.5\n",
      "Weight vector: [0.9 0.1 0.5]\n",
      "Final error: 0.7100799254006125\n",
      "final weight: [0.0753683  0.20997071 0.2007647 ]\n",
      "0.8\n",
      "0.5\n",
      "0.4\n",
      "Weight vector: [0.8 0.5 0.4]\n",
      "Final error: 0.8173768736109499\n",
      "final weight: [0.1283124  0.2935308  0.12572124]\n",
      "0.8\n",
      "0.8\n",
      "0.7\n",
      "Weight vector: [0.8 0.8 0.7]\n",
      "Final error: 0.801893920367123\n",
      "final weight: [0.11416024 0.2978249  0.13125067]\n",
      "0.7\n",
      "0.5\n",
      "0.3\n",
      "Weight vector: [0.7 0.5 0.3]\n",
      "Final error: 0.8089424659078588\n",
      "final weight: [0.11884561 0.29661664 0.1255488 ]\n",
      "0.8\n",
      "0.4\n",
      "0.7\n",
      "Weight vector: [0.8 0.4 0.7]\n",
      "Final error: 0.6841049753466427\n",
      "final weight: [0.05174935 0.21735065 0.20612169]\n",
      "0.0\n",
      "0.1\n",
      "0.3\n",
      "Weight vector: [0.  0.1 0.3]\n",
      "Final error: 0.5015019551150608\n",
      "final weight: [-0.1520735   0.1069329   0.34313901]\n",
      "0.4\n",
      "0.1\n",
      "0.2\n",
      "Weight vector: [0.4 0.1 0.2]\n",
      "Final error: 0.6124297890408741\n",
      "final weight: [-0.01260583  0.18802552  0.24102429]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#set alpha\n",
    "#initialise w with random numbers\n",
    "#set E to a large value (Emax)\n",
    "#iter = 0 \n",
    "#Repeat for until E < Emax or iter < maxIter\n",
    "#  E = 0\n",
    "#  for all training patterns {(x, d)}\n",
    "     # output y = Wx\n",
    "     # w = w + alpha*(d-y)*x\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "#weight_vector = np.zeros(3)\n",
    "#w = np.array([0.1, 0.1, 0.1]) #25 weights\n",
    "\n",
    "error_grp = []\n",
    "iter_grp = []\n",
    "#initialise the training patterns\n",
    "training = [[np.array([-0.5, 1.2, -0.1]).transpose(), 0.2], [np.array([0.7, -0.5, -0.2]).transpose(), -0.8], [np.array([0.3, 1.2, 2.3]).transpose(), 0.8], \n",
    "            [np.array([1.2, 0.8, 1.0]).transpose(), 0.4], [np.array([-0.5, 1.2, -0.1]).transpose(), -0.2],\n",
    "            [np.array([1.0, -0.3, 0.5]).transpose(), -0.1]]\n",
    "\n",
    "def lms(w): \n",
    "  i = 0\n",
    "  alpha = [0.1, 0.01, 0.001]\n",
    "  Emax = 10000000000000000000000000\n",
    "  maxIter = 500\n",
    "  E = 0\n",
    "  while ((i < maxIter) and (E < Emax)):\n",
    "    E = 0\n",
    "    for pair in training:\n",
    "      y = np.dot(w.transpose(), pair[0])\n",
    "      #print('y: ')\n",
    "      #print(y)\n",
    "      #print('==================')\n",
    "      w = w + np.dot((alpha[2]*(pair[1] - y)), pair[0])\n",
    "      #print('weight: ' + str(w))\n",
    "      E = E + np.power((pair[1] - y), 2)\n",
    "      #print('Error: ' + str(E))\n",
    "    #Put the error in the array after going thru the whole training pattern\n",
    "    error_grp.append(E)\n",
    "    iter_grp.append(i)\n",
    "    i = i + 1\n",
    "  #print('i: ' + str(i))\n",
    "\n",
    "  print('Final error: ' + str(E))\n",
    "  print('final weight: ' + str(w))\n",
    "\n",
    "w = []\n",
    "for x in range(25):\n",
    "  for y in range(3):\n",
    "    val = round(random.random(), 1)\n",
    "    print(val)\n",
    "    w.append(val)\n",
    "  weight_vector = np.array(w)\n",
    "  print('Weight vector: ' + str(weight_vector))\n",
    "  lms(weight_vector)\n",
    "  w = []\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "#Draw the graph\n",
    "plt.plot(iter_grp, error_grp)\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('No. of iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
